# sdg-hub-ui.container
# Purpose: Run SDG Hub with a simple UI (JupyterLab) sharing the same persistent host path.
# Image:   NVIDIA CUDA 12.6 + cuDNN on UBI9 (matches the other GPU units)
# PV:      Binds ~/instructlab-data -> /workspace  (shared with your other quadlets)

[Unit]
Description=SDG Hub UI (JupyterLab) - CUDA 12.6 cuDNN UBI9
After=network-online.target
Wants=network-online.target

[Container]
# --- Base image consistent with your stack ---
Image=docker.io/nvidia/cuda:12.6.0-cudnn-runtime-ubi9

# --- Naming & restart policy ---
ContainerName=sdg-hub-ui
Restart=always

# --- GPU enablement via NVIDIA OCI hooks (requires nvidia-container-toolkit on host) ---
# Environment=NVIDIA_VISIBLE_DEVICES=all
# Environment=NVIDIA_DRIVER_CAPABILITIES=compute,utility
AddDevice=nvidia.com/gpu=all

# -----------------------------
# SELinux options (Fedora/RHEL)
# -----------------------------
# Option A) Relaxed SELinux (default)
# - Simplest for GPU/CDI: disables the container SELinux label so /dev/nvidia* devices
#   and bind mounts work without extra labeling.
SecurityLabelDisable=true

# Option B) Strict SELinux (keep confinement)  <-- RECOMMENDED if you want strict policy
# - Comment OUT SecurityLabelDisable=true above
# - Add :z (shared) or :Z (private) to your bind mounts below
# - Ensure the host path is labeled and device use is allowed
#
#   Host prep (one-time):
#     sudo setsebool -P container_use_devices=true
#     sudo chcon -Rt container_file_t ~/instructlab-data
#
#   Volume lines with SELinux labels (uncomment one style):
# Volume=%h/instructlab-data:/workspace:z       # :z = shared label (multiple containers)
# Volume=%h/instructlab-data/.cache:/root/.cache:z
# Volume=%h/instructlab-data:/workspace:Z       # :Z = private label (isolated)
# Volume=%h/instructlab-data/.cache:/root/.cache:Z

# --- Shared persistent volume (same PV as your other quadlets) ---
# NOTE: keep this path identical across units so all share /workspace content.
Volume=%h/instructlab-data:/workspace
Volume=%h/instructlab-data/.cache:/root/.cache

# --- UI networking: bind to localhost:8999 by default ---
PublishPort=127.0.0.1:8999:8888/tcp

# --- Working directory for notebooks/repos ---
WorkingDir=/workspace

# --- Optional env: token & default notebook dir ---
Environment=JUPYTER_TOKEN=sdg
Environment=JUPYTER_NOTEBOOK_DIR=/workspace

# --- Command: install minimal deps, SDG Hub, and run JupyterLab ---
# SDG Hub install ref: README / PyPI (uv/pip install sdg-hub) 
# We keep it simple here with python+pip; swap to uv if you prefer.
Command=/bin/bash -lc "\
  dnf -y install python3.11 python3.11-pip git && \
  python3.11 -m pip install --upgrade pip && \
  python3.11 -m pip install jupyterlab sdg-hub && \
  jupyter lab \
    --ServerApp.token=${JUPYTER_TOKEN} \
    --ServerApp.root_dir=${JUPYTER_NOTEBOOK_DIR} \
    --ServerApp.allow_remote_access=1 \
    --ServerApp.ip=0.0.0.0 \
    --ServerApp.port=8888 \
    --ServerApp.open_browser=False \
"

[Service]
TimeoutStopSec=30
# Ensures NVIDIA kernel modules create /dev/nvidia-uvm before container start
ExecStartPre=/bin/bash -c 'while true; do /usr/bin/nvidia-smi -L && exit 0; sleep 1; done'

[Install]
WantedBy=default.target
